"""LLM-backed explanation and remediation helper for rules engine findings.

This module is import-safe and designed to be fully mockable in tests.
"""
from __future__ import annotations

from typing import Any, Dict, Optional
import os


def _call_llm(prompt: str, *, api_key: str) -> Dict[str, Any]:
    """Internal helper to call an LLM provider (OpenAI-compatible).

    This is deliberately simple and easy to mock in tests. To avoid
    introducing a hard dependency on the OpenAI SDK, we implement a
    minimal HTTP client only when an API key is present. In most
    environments, tests will patch this function directly.
    """

    import json
    import urllib.request

    # Use a generic OpenAI-compatible endpoint; can be overridden via env.
    base_url = os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1")
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    url = f"{base_url.rstrip('/')}/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    body = {
        "model": model,
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are a cloud security expert explaining IaC misconfigurations "
                    "and concise remediations for DevSecOps engineers."
                ),
            },
            {"role": "user", "content": prompt},
        ],
        "temperature": 0.2,
    }

    req = urllib.request.Request(url, data=json.dumps(body).encode("utf-8"), headers=headers)
    with urllib.request.urlopen(req, timeout=30) as resp:
        data = json.loads(resp.read().decode("utf-8"))

    message = (
        data.get("choices", [{}])[0]
        .get("message", {})
        .get("content", "")
        .strip()
    )

    return {"raw": data, "message": message}


def _deterministic_fallback(finding: Dict[str, Any], file_content: str) -> Dict[str, Any]:
    """Generate a deterministic explanation/remediation without external calls.

    This path is used when no API key is configured. It must be
    completely deterministic for testability.
    """

    rule_id = finding.get("rule_id") or finding.get("id") or "UNKNOWN_RULE"
    description = finding.get("description") or "Potential infrastructure-as-code risk detected."
    severity = finding.get("severity") or finding.get("level") or "UNKNOWN"
    file_path = finding.get("file_path") or finding.get("path") or "<unknown>"

    explanation = (
        f"Rule {rule_id} flagged this IaC resource as {severity}. "
        f"Description: {description}. "
        f"Location: {file_path}. "
        "This finding was generated by static analysis of the IaC file."
    )

    remediation = (
        "Review the flagged configuration and align it with your organization's "
        "cloud security best practices (for example, CIS Benchmarks or vendor "
        "hardening guides). Apply the least-privilege principle, avoid broad "
        "network exposure, and remove hard-coded secrets from the template."
    )

    # Fallback uses a medium certainty to indicate heuristic reasoning.
    return {
        "explanation": explanation,
        "remediation": remediation,
        "certainty": 0.6,
    }


def explain_and_remediate(finding: Dict[str, Any], file_content: str) -> Dict[str, Any]:
    """Return an LLM-backed or deterministic explanation/remediation for a finding.

    The return value is always a dict of the shape::

        {
          "explanation": str,
          "remediation": str,
          "certainty": float,  # between 0.0 and 1.0
        }

    If the environment variable ``OPENAI_API_KEY`` is not set, a
    deterministic template-based explanation is used. When it is set,
    this function attempts to call an OpenAI-compatible LLM endpoint via
    :func:`_call_llm` and parses a simple, robust response.
    """

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return _deterministic_fallback(finding, file_content)

    rule_id = finding.get("rule_id") or finding.get("id") or "UNKNOWN_RULE"
    description = finding.get("description") or "Potential IaC misconfiguration."
    severity = finding.get("severity") or finding.get("level") or "UNKNOWN"
    file_path = finding.get("file_path") or finding.get("path") or "<unknown>"

    # Construct a compact, structured prompt. This is intentionally
    # stable so tests can mock _call_llm predictably.
    snippet = file_content[:8000]
    prompt = (
        "You are helping to triage an Infrastructure-as-Code (IaC) finding.\n"  # noqa: E501
        f"Rule ID: {rule_id}\n"
        f"Severity: {severity}\n"
        f"Description: {description}\n"
        f"File path: {file_path}\n"
        "IaC snippet (may be truncated):\n" + snippet + "\n\n"  # noqa: E501
        "1) Briefly explain why this is risky in clear, practical terms.\n"  # noqa: E501
        "2) Provide a concrete remediation in 1-3 bullet points.\n"  # noqa: E501
        "3) Rate your certainty from 0.0 to 1.0 at the end as 'Certainty: X'."  # noqa: E501
    )

    try:
        resp = _call_llm(prompt, api_key=api_key)
        message = str(resp.get("message", "")).strip()
        if not message:
            raise ValueError("Empty LLM response")

        # Very lightweight certainty parsing: look for a trailing
        # 'Certainty: 0.xyz' token; fall back to 0.8 if missing.
        certainty: float = 0.8
        lower = message.lower()
        marker = "certainty:"
        if marker in lower:
            idx = lower.rfind(marker)
            tail = lower[idx + len(marker) :].strip()
            # Take first token that looks like a float.
            token = tail.split()[0]
            try:
                parsed = float(token)
                if 0.0 <= parsed <= 1.0:
                    certainty = parsed
            except ValueError:
                pass

        explanation = message
        remediation = "See the recommended remediation steps described above."

        return {
            "explanation": explanation,
            "remediation": remediation,
            "certainty": certainty,
        }
    except Exception:
        # Any runtime failure falls back to deterministic output so that
        # the rest of the pipeline continues to function.
        return _deterministic_fallback(finding, file_content)
